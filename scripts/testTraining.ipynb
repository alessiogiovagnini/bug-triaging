{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./.venv/lib/python3.10/site-packages (4.45.1)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (2.4.1)\n",
      "Requirement already satisfied: accelerate in ./.venv/lib/python3.10/site-packages (0.34.2)\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: evaluate in ./.venv/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: cryptography~=43.0.1 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (43.0.1)\n",
      "Requirement already satisfied: pip~=23.2.1 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (23.2.1)\n",
      "Requirement already satisfied: PyGithub~=2.4.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: PyJWT~=2.9.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.9.0)\n",
      "Requirement already satisfied: requests~=2.32.3 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (2.32.3)\n",
      "Requirement already satisfied: Deprecated~=1.2.14 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.2.14)\n",
      "Requirement already satisfied: urllib3~=2.2.3 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (2.2.3)\n",
      "Requirement already satisfied: typing_extensions~=4.12.2 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (4.12.2)\n",
      "Requirement already satisfied: certifi~=2024.8.30 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (2024.8.30)\n",
      "Requirement already satisfied: idna~=3.10 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (3.10)\n",
      "Requirement already satisfied: pycparser~=2.22 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.22)\n",
      "Requirement already satisfied: wrapt~=1.16.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (1.16.0)\n",
      "Requirement already satisfied: python-dotenv~=1.0.1 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.0.1)\n",
      "Requirement already satisfied: marko~=2.1.2 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (2.1.2)\n",
      "Requirement already satisfied: cleantext~=1.1.4 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (1.1.4)\n",
      "Requirement already satisfied: demoji==1.1.0 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (1.1.0)\n",
      "Requirement already satisfied: flask~=3.0.3 in ./.venv/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./.venv/lib/python3.10/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./.venv/lib/python3.10/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./.venv/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./.venv/lib/python3.10/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.77)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.10/site-packages (from datasets) (3.10.8)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.12 in ./.venv/lib/python3.10/site-packages (from cryptography~=43.0.1->-r requirements.txt (line 1)) (1.17.1)\n",
      "Requirement already satisfied: pynacl>=1.4.0 in ./.venv/lib/python3.10/site-packages (from PyGithub~=2.4.0->-r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests~=2.32.3->-r requirements.txt (line 5)) (3.3.2)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.10/site-packages (from cleantext~=1.1.4->-r requirements.txt (line 15)) (3.9.1)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in ./.venv/lib/python3.10/site-packages (from flask~=3.0.3->-r requirements.txt (line 18)) (3.0.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in ./.venv/lib/python3.10/site-packages (from flask~=3.0.3->-r requirements.txt (line 18)) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in ./.venv/lib/python3.10/site-packages (from flask~=3.0.3->-r requirements.txt (line 18)) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in ./.venv/lib/python3.10/site-packages (from flask~=3.0.3->-r requirements.txt (line 18)) (1.8.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.13.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch accelerate datasets evaluate numpy pandas scikit-learn -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "isCuda = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this if using the gym NVIDIA GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "isCuda = True\n",
    "isTraining = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cleaning_tool as ct\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('training_set.csv')\n",
    "df = df.dropna()\n",
    "df = ct.filter_single_users(dataframe=df, min_pull=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingSet lenght: 110305\n",
      "evaluationSet lenght: 11926\n",
      "testSet length: 2850\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the assignee names\n",
    "label_encoder = LabelEncoder()\n",
    "df['assignee_encoded'] = label_encoder.fit_transform(df['assignee'])\n",
    "\n",
    "df['input_text'] = \"<#TITLE-START#> \" + df['title'] + \" <#TITLE-END#> <#BODY-START#> \" + df['body'] + \" <#BODY-END#>\"\n",
    "\n",
    "\n",
    "# Split into input features (titles) and labels (encoded assignees)\n",
    "titles = df['input_text'].tolist()\n",
    "\n",
    "trainingSet = df[df['number'] < 185000]['input_text'].tolist()\n",
    "evaluationSet = df[ (185000 <= df['number']) & (df['number']< 210000)]['input_text'].tolist()\n",
    "testSet = df[(210000 <= df['number']) & (df['number']< 220000)]['input_text'].tolist()\n",
    "\n",
    "labels = df['assignee_encoded'].tolist()\n",
    "\n",
    "trainingLabels = df[df['number'] < 185000]['assignee_encoded'].tolist()\n",
    "evaluationLabels = df[ (185000 <= df['number']) & (df['number']< 210000)]['assignee_encoded'].tolist()\n",
    "testLabels = df[(210000 <= df['number']) & (df['number']< 220000)]['assignee_encoded'].tolist()\n",
    "\n",
    "print('trainingSet lenght:', len(trainingSet))\n",
    "print('evaluationSet lenght:', len(evaluationSet))\n",
    "print('testSet length:', len(testSet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/casarf/Documents/USI/Master/semester3/SoftwareAnalytics/project/bug-triaging/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Choose a model, e.g., 'distilbert-base-uncased'\n",
    "# model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize the input titles\n",
    "# inputs = tokenizer(titles, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "# inputs = tokenizer(titles, padding=True, truncation=True, return_tensors='pt', max_length=128).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def makeDataset(current, labels, isCuda):\n",
    "    if isCuda:\n",
    "        inputs = tokenizer(current, padding=True, truncation=True, return_tensors='pt', max_length=128).to(\"cuda\")\n",
    "    else:\n",
    "        inputs = tokenizer(current, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "    \n",
    "    return Dataset.from_dict({\n",
    "    'input_ids': inputs['input_ids'],\n",
    "    'attention_mask': inputs['attention_mask'],\n",
    "    'labels': labels\n",
    "})\n",
    "\n",
    "trainingSet = makeDataset(trainingSet, trainingLabels, isCuda)\n",
    "evaluationSet =  makeDataset(evaluationSet, evaluationLabels, isCuda)\n",
    "testSet =  makeDataset(testSet, testLabels, isCuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Load metric functions\n",
    "accuracy_metric = evaluate.load('accuracy')\n",
    "precision_metric = evaluate.load('precision')\n",
    "recall_metric = evaluate.load('recall')\n",
    "f1_metric = evaluate.load('f1')\n",
    "\n",
    "# Define compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average='weighted', zero_division=0)\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy['accuracy'],\n",
    "        'precision': precision['precision'],\n",
    "        'recall': recall['recall'],\n",
    "        'f1': f1['f1'],\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this to train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_encoder.classes_))\n",
    "\n",
    "# Define training arguments with early stopping and final model saving\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',  # Evaluate at the end of each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='epoch',  # Save at the end of each epoch\n",
    "    save_total_limit=1,  # Keep only the most recent model\n",
    "    load_best_model_at_end=True,  # Automatically load the best model at the end\n",
    "    metric_for_best_model='eval_loss',  # Use validation loss to select the best model\n",
    "    greater_is_better=False,  # Lower loss is better\n",
    ")\n",
    "\n",
    "# Create the Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=trainingSet,\n",
    "    eval_dataset=evaluationSet,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],  # Early stopping with patience\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the produced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(testSet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import json\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('./results/checkpoint-14102024')\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "with open(\"labels_json.json\") as f:\n",
    "    labelsFromJson = json.load(f)\n",
    "isTraining = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/casarf/Documents/USI/Master/semester3/SoftwareAnalytics/project/bug-triaging/.venv/lib/python3.12/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ab8aca0de748408d929651284858d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/casarf/Documents/USI/Master/semester3/SoftwareAnalytics/project/bug-triaging/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.25747013092041,\n",
       " 'eval_model_preparation_time': 0.0007,\n",
       " 'eval_accuracy': 0.5126315789473684,\n",
       " 'eval_precision': 0.5207645832636719,\n",
       " 'eval_recall': 0.5126315789473684,\n",
       " 'eval_f1': 0.4967896014119016,\n",
       " 'eval_runtime': 9.6767,\n",
       " 'eval_samples_per_second': 294.522,\n",
       " 'eval_steps_per_second': 4.65}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',  # Evaluate at the end of each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='epoch',  # Save at the end of each epoch\n",
    "    save_total_limit=1,  # Keep only the most recent model\n",
    "    load_best_model_at_end=True,  # Automatically load the best model at the end\n",
    "    metric_for_best_model='eval_loss',  # Use validation loss to select the best model\n",
    "    greater_is_better=False,  # Lower loss is better\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=trainingSet,\n",
    "    eval_dataset=evaluationSet,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],  # Early stopping with patience\n",
    ")\n",
    "\n",
    "trainer.evaluate(testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: sbatten: 0.75\n",
      "2: bpasero: 0.15\n",
      "3: deepak1556: 0.04\n",
      "4: isidorn: 0.02\n",
      "5: joaomoreno: 0.01\n",
      "6: miguelsolorio: 0.01\n",
      "7: jrieken: 0.00\n",
      "8: sandy081: 0.00\n",
      "9: Tyriar: 0.00\n",
      "10: daviddossett: 0.00\n",
      "11: lramos15: 0.00\n",
      "12: eamodio: 0.00\n",
      "13: mjbvz: 0.00\n",
      "14: alexr00: 0.00\n",
      "15: JacksonKearl: 0.00\n",
      "16: aeschli: 0.00\n",
      "17: roblourens: 0.00\n",
      "18: stevencl: 0.00\n",
      "19: chrmarti: 0.00\n",
      "20: TylerLeonhardt: 0.00\n",
      "21: connor4312: 0.00\n",
      "22: meganrogge: 0.00\n",
      "23: rzhao271: 0.00\n",
      "24: alexdima: 0.00\n",
      "25: lszomoru: 0.00\n",
      "26: joyceerhl: 0.00\n",
      "27: rebornix: 0.00\n",
      "28: egamma: 0.00\n",
      "29: cleidigh: 0.00\n",
      "30: chrisdias: 0.00\n",
      "31: RMacfarlane: 0.00\n",
      "32: bhavyaus: 0.00\n",
      "33: bgashler1: 0.00\n",
      "34: hediet: 0.00\n",
      "35: weinand: 0.00\n",
      "36: dbaeumer: 0.00\n",
      "37: benibenj: 0.00\n",
      "38: octref: 0.00\n",
      "39: michelkaporin: 0.00\n",
      "40: andreamah: 0.00\n",
      "41: justschen: 0.00\n",
      "42: seanmcbreen: 0.00\n",
      "43: tanhakabir: 0.00\n",
      "44: ramya-rao-a: 0.00\n",
      "45: ulugbekna: 0.00\n",
      "46: kieferrm: 0.00\n",
      "47: DonJayamanne: 0.00\n",
      "48: gregvanl: 0.00\n",
      "49: digitarald: 0.00\n",
      "50: aiday-mar: 0.00\n",
      "51: danyeh: 0.00\n",
      "52: tsalinger: 0.00\n",
      "53: auchenberg: 0.00\n",
      "54: vsccarl: 0.00\n",
      "55: sofianhn: 0.00\n",
      "56: waderyan: 0.00\n",
      "57: amunger: 0.00\n",
      "58: sana-ajani: 0.00\n",
      "59: fiveisprime: 0.00\n",
      "60: Lixire: 0.00\n",
      "61: lukaschal: 0.00\n",
      "62: paulacamargo25: 0.00\n",
      "63: mousetraps: 0.00\n",
      "64: karthiknadig: 0.00\n",
      "65: johnliu369: 0.00\n",
      "66: v-pavanp: 0.00\n",
      "67: eleanorjboyd: 0.00\n",
      "68: 9at8: 0.00\n",
      "69: karrtikr: 0.00\n",
      "70: Yoyokrazy: 0.00\n",
      "71: rchiodo: 0.00\n",
      "72: bamurtaugh: 0.00\n",
      "73: daviwil: 0.00\n",
      "74: hbons: 0.00\n",
      "75: gushuro: 0.00\n",
      "76: brettcannon: 0.00\n",
      "77: IanMatthewHuff: 0.00\n",
      "78: MeghanKulkarni: 0.00\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Move the model to the correct device\n",
    "model.to(device)\n",
    "\n",
    "def predict_assignee(title, body):\n",
    "    # Concatenate title and body\n",
    "    combined_input = title + \" \" + body\n",
    "    \n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(combined_input, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    \n",
    "    # Move input tensors to the correct device\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    # Get model output\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    # Get logits\n",
    "    logits = outputs.logits.detach().cpu().numpy()[0]\n",
    "    \n",
    "    # Get probabilities using softmax\n",
    "    probabilities = softmax(logits)\n",
    "    \n",
    "    # Create a list of (assignee, probability) pairs\n",
    "    if isTraining:\n",
    "        assignee_probs = list(zip(label_encoder.classes_, probabilities))\n",
    "    else:\n",
    "        assignee_probs = list(zip(labelsFromJson, probabilities))\n",
    "    \n",
    "    # Sort by probability in descending order\n",
    "    ranked_assignees = sorted(assignee_probs, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return ranked_assignees\n",
    "\n",
    "# Example prediction with both title and body\n",
    "ranked_list = predict_assignee(\"Side bar always showing when opening VS Code\", \"When opening VS Code, the sidebar is always visible\")\n",
    "\n",
    "for index, (assignee, probability) in enumerate(ranked_list):\n",
    "    print(f\"{index + 1}: {assignee}: {probability:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4123887/1114867945.py:5: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  device = torch.device('mps') if torch.has_mps else torch.device('cpu')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'label_encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ranked_assignees\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Example prediction with both title and body\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m ranked_list \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_assignee\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSide bar always showing when opening VS Code\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhen opening VS Code, the sidebar is always visible\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, (assignee, probability) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ranked_list):\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00massignee\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprobability\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 49\u001b[0m, in \u001b[0;36mpredict_assignee\u001b[0;34m(title, body)\u001b[0m\n\u001b[1;32m     46\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m softmax(logits)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Create a list of (assignee, probability) pairs\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m assignee_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241m.\u001b[39mclasses_, probabilities))\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Sort by probability in descending order\u001b[39;00m\n\u001b[1;32m     52\u001b[0m ranked_assignees \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(assignee_probs, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label_encoder' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Check if MPS is available\n",
    "device = torch.device('mps') if torch.has_mps else torch.device('cpu')\n",
    "\n",
    "# Move the model to the correct device\n",
    "model.to(device)\n",
    "\n",
    "# def predict_assignee(title):\n",
    "#     # Tokenize the input\n",
    "#     inputs = tokenizer(title, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "\n",
    "#     # Move input tensors to the correct device\n",
    "#     inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "#     # Get model output\n",
    "#     outputs = model(**inputs)\n",
    "\n",
    "#     # Get the predicted class\n",
    "#     predicted_class = outputs.logits.argmax(dim=1).item()\n",
    "\n",
    "#     # Return the assignee name\n",
    "#     return label_encoder.inverse_transform([predicted_class])[0]\n",
    "\n",
    "# Example prediction\n",
    "# print(predict_assignee(\"Change the name\"))\n",
    "\n",
    "def predict_assignee(title, body):\n",
    "    # Concatenate title and body\n",
    "    combined_input = title + \" \" + body\n",
    "    \n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(combined_input, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    \n",
    "    # Move input tensors to the correct device\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    # Get model output\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    # Get logits\n",
    "    logits = outputs.logits.detach().cpu().numpy()[0]\n",
    "    \n",
    "    # Get probabilities using softmax\n",
    "    probabilities = softmax(logits)\n",
    "    \n",
    "    # Create a list of (assignee, probability) pairs\n",
    "    if isTraining:\n",
    "        assignee_probs = list(zip(label_encoder.classes_, probabilities))\n",
    "    else:\n",
    "        assignee_probs = list(zip(labelsFromJson, probabilities))\n",
    "    \n",
    "    # Sort by probability in descending order\n",
    "    ranked_assignees = sorted(assignee_probs, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return ranked_assignees\n",
    "\n",
    "# Example prediction with both title and body\n",
    "ranked_list = predict_assignee(\"Side bar always showing when opening VS Code\", \"When opening VS Code, the sidebar is always visible\")\n",
    "\n",
    "for index, (assignee, probability) in enumerate(ranked_list):\n",
    "    print(f\"{index + 1}: {assignee}: {probability:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
